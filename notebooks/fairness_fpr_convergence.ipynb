{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c61c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = sage.datasets.credit()\n",
    "\n",
    "# Feature names and categorical columns (for CatBoost model)\n",
    "feature_names = df.columns.tolist()[:-1]\n",
    "categorical_columns = [\n",
    "    'Checking Status', 'Credit History', 'Purpose', 'Credit Amount',\n",
    "    'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "    'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "    'Housing Ownership', 'Job', 'Telephone', 'Foreign Worker'\n",
    "]\n",
    "categorical_inds = [feature_names.index(col) for col in categorical_columns]\n",
    "\n",
    "# Split data\n",
    "train, test = train_test_split(\n",
    "    df.values, test_size=int(0.1 * len(df.values)), random_state=0)\n",
    "train, val = train_test_split(\n",
    "    train, test_size=int(0.1 * len(df.values)), random_state=0)\n",
    "Y_train = train[:, -1].copy().astype(int)\n",
    "Y_val = val[:, -1].copy().astype(int)\n",
    "Y_test = test[:, -1].copy().astype(int)\n",
    "train = train[:, :-1].copy()\n",
    "val = val[:, :-1].copy()\n",
    "test = test[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfab69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "model_filename = \"../credit_model.cbm\"\n",
    "\n",
    "if os.path.isfile(model_filename):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(model_filename)\n",
    "else:\n",
    "    model = CatBoostClassifier(iterations=50, learning_rate=0.3, depth=3)\n",
    "    model = model.fit(train, Y_train, categorical_inds, eval_set=(val, Y_val), verbose=False)\n",
    "    model.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75864bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base rate cross entropy = 0.602\n",
      "Model cross entropy = 0.457\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# Calculate performance\n",
    "p = np.array([np.sum(Y_train == i) for i in np.unique(Y_train)]) / len(Y_train)\n",
    "base_ce = log_loss(Y_test.astype(int), p[np.newaxis].repeat(len(test), 0))\n",
    "ce = log_loss(Y_test.astype(int), model.predict_proba(test))\n",
    "\n",
    "print('Base rate cross entropy = {:.3f}'.format(base_ce))\n",
    "print('Model cross entropy = {:.3f}'.format(ce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dceb930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score = 0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"ROC AUC Score = {:.3f}\".format(roc_auc_score(Y_test, model.predict_proba(test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fea452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative rate = 0.042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_test = model.predict_proba(test)\n",
    "pred_test = np.argmax(pred_test, axis=1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, pred_test, labels=[0,1]).ravel()\n",
    "p = tp + fn\n",
    "fnr = fn / p if p > 0.0 else np.float64(0.0)\n",
    "\n",
    "print(\"False negative rate = {:.3f}\".format(fnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe7060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier got 3 positive examples wrong\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier got {} positive examples wrong\".format(int(round(Y_test.sum() * fnr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9ab1d",
   "metadata": {},
   "source": [
    "# Global FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d7da79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f34434c8894a4398923489cd2e875f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = 0, p = 366, fnr = 0.0\n",
      "===> Iteration 0, Prev loss = 0.0 [outer loop]\n",
      "fn = 0, p = 366, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 366, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 366, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 1, p = 366, fnr = 0.00273224043715847\n",
      "\tLoss = 0.00273224043715847 [inner loop]\n",
      "fn = 1, p = 366, fnr = 0.00273224043715847\n",
      "\tLoss = 0.00273224043715847 [inner loop]\n",
      "fn = 1, p = 366, fnr = 0.00273224043715847\n",
      "\tLoss = 0.00273224043715847 [inner loop]\n",
      "fn = 2, p = 366, fnr = 0.00546448087431694\n",
      "\tLoss = 0.00546448087431694 [inner loop]\n",
      "fn = 1, p = 366, fnr = 0.00273224043715847\n",
      "\tLoss = 0.00273224043715847 [inner loop]\n",
      "fn = 2, p = 366, fnr = 0.00546448087431694\n",
      "\tLoss = 0.00546448087431694 [inner loop]\n",
      "fn = 2, p = 366, fnr = 0.00546448087431694\n",
      "\tLoss = 0.00546448087431694 [inner loop]\n",
      "fn = 4, p = 366, fnr = 0.01092896174863388\n",
      "\tLoss = 0.01092896174863388 [inner loop]\n",
      "fn = 4, p = 366, fnr = 0.01092896174863388\n",
      "\tLoss = 0.01092896174863388 [inner loop]\n",
      "fn = 6, p = 366, fnr = 0.01639344262295082\n",
      "\tLoss = 0.01639344262295082 [inner loop]\n",
      "fn = 8, p = 366, fnr = 0.02185792349726776\n",
      "\tLoss = 0.02185792349726776 [inner loop]\n",
      "fn = 7, p = 366, fnr = 0.01912568306010929\n",
      "\tLoss = 0.01912568306010929 [inner loop]\n",
      "fn = 8, p = 366, fnr = 0.02185792349726776\n",
      "\tLoss = 0.02185792349726776 [inner loop]\n",
      "fn = 10, p = 366, fnr = 0.0273224043715847\n",
      "\tLoss = 0.0273224043715847 [inner loop]\n",
      "fn = 7, p = 366, fnr = 0.01912568306010929\n",
      "\tLoss = 0.01912568306010929 [inner loop]\n",
      "fn = 7, p = 366, fnr = 0.01912568306010929\n",
      "\tLoss = 0.01912568306010929 [inner loop]\n",
      "fn = 9, p = 366, fnr = 0.02459016393442623\n",
      "\tLoss = 0.02459016393442623 [inner loop]\n",
      "StdDev Ratio = 0.3246 (Converge at 0.0250)\n",
      "fn = 0, p = 379, fnr = 0.0\n",
      "===> Iteration 1, Prev loss = 0.0 [outer loop]\n",
      "fn = 0, p = 379, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 379, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 1, p = 379, fnr = 0.002638522427440633\n",
      "\tLoss = 0.002638522427440633 [inner loop]\n",
      "fn = 2, p = 379, fnr = 0.005277044854881266\n",
      "\tLoss = 0.005277044854881266 [inner loop]\n",
      "fn = 2, p = 379, fnr = 0.005277044854881266\n",
      "\tLoss = 0.005277044854881266 [inner loop]\n",
      "fn = 3, p = 379, fnr = 0.0079155672823219\n",
      "\tLoss = 0.0079155672823219 [inner loop]\n",
      "fn = 5, p = 379, fnr = 0.013192612137203167\n",
      "\tLoss = 0.013192612137203167 [inner loop]\n",
      "fn = 7, p = 379, fnr = 0.018469656992084433\n",
      "\tLoss = 0.018469656992084433 [inner loop]\n",
      "fn = 9, p = 379, fnr = 0.023746701846965697\n",
      "\tLoss = 0.023746701846965697 [inner loop]\n",
      "fn = 11, p = 379, fnr = 0.029023746701846966\n",
      "\tLoss = 0.029023746701846966 [inner loop]\n",
      "fn = 15, p = 379, fnr = 0.0395778364116095\n",
      "\tLoss = 0.0395778364116095 [inner loop]\n",
      "fn = 14, p = 379, fnr = 0.036939313984168866\n",
      "\tLoss = 0.036939313984168866 [inner loop]\n",
      "fn = 16, p = 379, fnr = 0.04221635883905013\n",
      "\tLoss = 0.04221635883905013 [inner loop]\n",
      "fn = 17, p = 379, fnr = 0.044854881266490766\n",
      "\tLoss = 0.044854881266490766 [inner loop]\n",
      "fn = 18, p = 379, fnr = 0.047493403693931395\n",
      "\tLoss = 0.047493403693931395 [inner loop]\n",
      "fn = 23, p = 379, fnr = 0.06068601583113457\n",
      "\tLoss = 0.06068601583113457 [inner loop]\n",
      "fn = 26, p = 379, fnr = 0.06860158311345646\n",
      "\tLoss = 0.06860158311345646 [inner loop]\n",
      "fn = 27, p = 379, fnr = 0.0712401055408971\n",
      "\tLoss = 0.0712401055408971 [inner loop]\n",
      "fn = 27, p = 379, fnr = 0.0712401055408971\n",
      "\tLoss = 0.0712401055408971 [inner loop]\n",
      "fn = 28, p = 379, fnr = 0.07387862796833773\n",
      "\tLoss = 0.07387862796833773 [inner loop]\n",
      "StdDev Ratio = 0.2539 (Converge at 0.0250)\n",
      "fn = 0, p = 363, fnr = 0.0\n",
      "===> Iteration 2, Prev loss = 0.0 [outer loop]\n",
      "fn = 0, p = 363, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 363, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 363, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 2, p = 363, fnr = 0.005509641873278237\n",
      "\tLoss = 0.005509641873278237 [inner loop]\n",
      "fn = 3, p = 363, fnr = 0.008264462809917356\n",
      "\tLoss = 0.008264462809917356 [inner loop]\n",
      "fn = 4, p = 363, fnr = 0.011019283746556474\n",
      "\tLoss = 0.011019283746556474 [inner loop]\n",
      "fn = 5, p = 363, fnr = 0.013774104683195593\n",
      "\tLoss = 0.013774104683195593 [inner loop]\n",
      "fn = 6, p = 363, fnr = 0.01652892561983471\n",
      "\tLoss = 0.01652892561983471 [inner loop]\n",
      "fn = 7, p = 363, fnr = 0.01928374655647383\n",
      "\tLoss = 0.01928374655647383 [inner loop]\n",
      "fn = 8, p = 363, fnr = 0.02203856749311295\n",
      "\tLoss = 0.02203856749311295 [inner loop]\n",
      "fn = 12, p = 363, fnr = 0.03305785123966942\n",
      "\tLoss = 0.03305785123966942 [inner loop]\n",
      "fn = 16, p = 363, fnr = 0.0440771349862259\n",
      "\tLoss = 0.0440771349862259 [inner loop]\n",
      "fn = 17, p = 363, fnr = 0.046831955922865015\n",
      "\tLoss = 0.046831955922865015 [inner loop]\n",
      "fn = 18, p = 363, fnr = 0.049586776859504134\n",
      "\tLoss = 0.049586776859504134 [inner loop]\n",
      "fn = 18, p = 363, fnr = 0.049586776859504134\n",
      "\tLoss = 0.049586776859504134 [inner loop]\n",
      "fn = 19, p = 363, fnr = 0.05234159779614325\n",
      "\tLoss = 0.05234159779614325 [inner loop]\n",
      "fn = 20, p = 363, fnr = 0.05509641873278237\n",
      "\tLoss = 0.05509641873278237 [inner loop]\n",
      "fn = 23, p = 363, fnr = 0.06336088154269973\n",
      "\tLoss = 0.06336088154269973 [inner loop]\n",
      "fn = 24, p = 363, fnr = 0.06611570247933884\n",
      "\tLoss = 0.06611570247933884 [inner loop]\n",
      "fn = 22, p = 363, fnr = 0.06060606060606061\n",
      "\tLoss = 0.06060606060606061 [inner loop]\n",
      "StdDev Ratio = 0.2556 (Converge at 0.0250)\n",
      "fn = 0, p = 369, fnr = 0.0\n",
      "===> Iteration 3, Prev loss = 0.0 [outer loop]\n",
      "fn = 0, p = 369, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 0, p = 369, fnr = 0.0\n",
      "\tLoss = 0.0 [inner loop]\n",
      "fn = 1, p = 369, fnr = 0.0027100271002710027\n",
      "\tLoss = 0.0027100271002710027 [inner loop]\n",
      "fn = 3, p = 369, fnr = 0.008130081300813009\n",
      "\tLoss = 0.008130081300813009 [inner loop]\n",
      "fn = 5, p = 369, fnr = 0.013550135501355014\n",
      "\tLoss = 0.013550135501355014 [inner loop]\n",
      "fn = 5, p = 369, fnr = 0.013550135501355014\n",
      "\tLoss = 0.013550135501355014 [inner loop]\n",
      "fn = 7, p = 369, fnr = 0.018970189701897018\n",
      "\tLoss = 0.018970189701897018 [inner loop]\n",
      "fn = 8, p = 369, fnr = 0.02168021680216802\n",
      "\tLoss = 0.02168021680216802 [inner loop]\n",
      "fn = 7, p = 369, fnr = 0.018970189701897018\n",
      "\tLoss = 0.018970189701897018 [inner loop]\n",
      "fn = 7, p = 369, fnr = 0.018970189701897018\n",
      "\tLoss = 0.018970189701897018 [inner loop]\n",
      "fn = 8, p = 369, fnr = 0.02168021680216802\n",
      "\tLoss = 0.02168021680216802 [inner loop]\n",
      "fn = 10, p = 369, fnr = 0.02710027100271003\n",
      "\tLoss = 0.02710027100271003 [inner loop]\n",
      "fn = 9, p = 369, fnr = 0.024390243902439025\n",
      "\tLoss = 0.024390243902439025 [inner loop]\n",
      "fn = 9, p = 369, fnr = 0.024390243902439025\n",
      "\tLoss = 0.024390243902439025 [inner loop]\n",
      "fn = 9, p = 369, fnr = 0.024390243902439025\n",
      "\tLoss = 0.024390243902439025 [inner loop]\n",
      "fn = 8, p = 369, fnr = 0.02168021680216802\n",
      "\tLoss = 0.02168021680216802 [inner loop]\n",
      "fn = 9, p = 369, fnr = 0.024390243902439025\n",
      "\tLoss = 0.024390243902439025 [inner loop]\n",
      "fn = 15, p = 369, fnr = 0.04065040650406504\n",
      "\tLoss = 0.04065040650406504 [inner loop]\n",
      "fn = 15, p = 369, fnr = 0.04065040650406504\n",
      "\tLoss = 0.04065040650406504 [inner loop]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/sage/permutation_estimator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, batch_size, detect_convergence, thresh, n_permutations, min_coalition, max_coalition, verbose, bar, check_in_sensitive_group)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# Make prediction with missing features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_sensitive_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_sensitive_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/sage/imputers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, S)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Make predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/sage/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'catboost.CatBoostClassifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'catboost.CatBoostRegressor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   4808\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevery\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4809\u001b[0m         \"\"\"\n\u001b[0;32m-> 4810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_predict_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2201\u001b[0m                 \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_embedding_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                 \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthread_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m             )\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_single_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    626\u001b[0m                     )\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dataresponsibly/fairdeploy/sage/sage-env/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, thread_count)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_if_pandas_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timestamp_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sage_values_fnr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zw/50wf7xcd0cvfp98zy5gph_qr0000gn/T/ipykernel_19479/1000148781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SAGE values using false negative rate as loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msage_values_fnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sage_values_fnr' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup and calculate with custom fairness-related loss function\n",
    "imputer = sage.MarginalImputer(model, train[:512])\n",
    "estimator_fpr = sage.PermutationEstimator(imputer, 'fpr')\n",
    "%time sage_values_fpr = estimator_fpr(test, Y_test, verbose=True)\n",
    "\n",
    "# Print results\n",
    "print(\"SAGE values using false positive rate as loss:\", sage_values_fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_values_fpr.plot(feature_names, title='Feature Importance with respect to Global False Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3a1c1",
   "metadata": {},
   "source": [
    "# Young group FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = feature_names.index(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_young_train = train[:,age_col] <= 30\n",
    "where_young_test = test[:,age_col] <= 30\n",
    "\n",
    "test_young = test[where_young_test]\n",
    "Y_test_young = Y_test[where_young_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ac4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and calculate with custom fairness-related loss function\n",
    "imputer_young = sage.MarginalImputer(model, train[where_young_train])\n",
    "estimator_young_fpr = sage.PermutationEstimator(imputer_young, 'fpr')\n",
    "%time sage_values_young_fpr = estimator_young_fpr(test_young, Y_test_young, verbose=True)\n",
    "\n",
    "# Print results\n",
    "print(\"SAGE values using false positive rate as loss:\", sage_values_young_fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_values_young_fpr.plot(feature_names, title='Feature Importance with respect to Young Group\\'s False Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d452c7",
   "metadata": {},
   "source": [
    "# Old group FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_old_train = train[:,age_col] > 30\n",
    "where_old_test = np.invert(where_young_test)\n",
    "\n",
    "test_old = test[where_old_test]\n",
    "Y_test_old = Y_test[where_old_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and calculate with custom fairness-related loss function\n",
    "imputer_old = sage.MarginalImputer(model, train[where_old_train])\n",
    "estimator_old_fpr = sage.PermutationEstimator(imputer_old, 'fpr')\n",
    "%time sage_values_old_fnr = estimator_old_fr(test_old, Y_test_old, verbose=True)\n",
    "\n",
    "# Print results\n",
    "print(\"SAGE values using false negative rate as loss:\", sage_values_old_fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62071775",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_values_old_fnr.plot(feature_names, title='Feature Importance with respect to Old Group\\'s False Negative Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
